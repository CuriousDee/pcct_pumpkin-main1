import os
import io
import json
import threading
import time
from flask import Flask, render_template, Response, request, jsonify
import cv2
import numpy as np
import random

# Import processing helpers from face1 (we'll reuse some functions)
from face1 import overlay_transparent, load_overlays, face_cascade
try:
    from llama_cpp import Llama
    LLAMA_AVAILABLE = True
except ImportError:
    LLAMA_AVAILABLE = False

app = Flask(__name__)

# Ensure models directory exists
models_dir = os.path.join(os.path.dirname(__file__), "models")
os.makedirs(models_dir, exist_ok=True)

# Use a smaller model that's more likely to work on most systems
LLAMA_MODEL_PATH = os.path.join(models_dir, "llama-2-7b-chat.q2_K.gguf")  # Smaller quantized model

# Global state shared between HTTP handlers and capture thread
state = {
    "overlays_dir": os.path.join(os.path.dirname(__file__), "overlays"),
    "snapshots_dir": os.path.join(os.path.dirname(__file__), "snapshots"),
    "overlays": [],
    "current_idx": 0,
    "_overlays_signature": (),
    "overlay_lookup": {},
    "active_overlays": [],
    "show_face_box": False,
    "face_box_thickness": 1,
    "frame": None,
    "running": True,
    "nudge_mode": False,
    "nudge_overlay": None,
    "nudge_message": "",
    "fps": 0.0,
    "mode": "prod",
    "prod_frozen": False,
    "prod_frame": None,
    "prod_waiting": False,
    "last_snapshot_path": None,
    "story_text": "",
    "story_updated": None,
}

STORY_TEMPLATES = [
    # Spooky
    "{name} haunts the office in a {costume}, lurking near the {treat}. Employees scream!",
    "Dressed as a {costume}, {name} casts a spooky shadow while reaching for a {treat}.",
    "The office was never the same after {name} came as a {costume}, bringing a mysterious {treat}.",
    "On Halloween, {name} transformed the break room into a spooky scene with their {costume} and a {treat}.",
    # Funny
    "{name} in a {costume} couldn't stop laughing while tripping over a pile of {treat}s.",
    "The real treat was {name}'s {costume}, especially when they danced for candy!",
    "When the boss asked for a report, {name} in a {costume} just handed over a {treat} instead.",
    "Everyone expected a scare, but {name} brought laughs in their {costume} and a bag of {treat}s.",
    # Halloweeny
    "It was a classic Halloween in the office with {name} as a {costume}, handing out {treat}s.",
    "{name}'s desk was the place to be for Halloween, featuring a {costume} and a big bowl of {treat}s.",
    "The sight of {name} in a {costume} brought Halloween spirit, especially with their {treat} stash.",
    "Legends say {name} still roams the office in their {costume}, guarding the secret candy {treat}.",
    # Adventurous
    "The adventure began when {name} in a {costume} found a mysterious {treat} map in the office.",
    "{name} donned their {costume} and followed the {treat} trail to uncover office secrets.",
    "With a {costume} and a brave heart, {name} ventured into the haunted server room for a {treat}.",
    "It was a race against time as {name} in a {costume} sought the legendary {treat} of the office.",
]

# Set model path to models directory
# LLAMA_MODEL_PATH = os.path.join(os.path.dirname(__file__), "models", "mistral-7b-instruct-v0.2.Q4_K_M.gguf") # Update filename if needed
llm_instance = None

def verify_model_file():
    if not os.path.exists(LLAMA_MODEL_PATH):
        print(f"Model file not found at: {LLAMA_MODEL_PATH}")
        print("Please download the model file from: https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf")
        print("And place it in the 'models' directory")
        return False
    
    try:
        with open(LLAMA_MODEL_PATH, 'rb') as f:
            magic = f.read(4)
            if magic != b'GGUF':
                print(f"Invalid model file format. File does not appear to be a valid GGUF model.")
                return False
    except Exception as e:
        print(f"Error reading model file: {e}")
        return False
    return True

def get_llm():
    global llm_instance
    if not LLAMA_AVAILABLE:
        print("llama-cpp-python not installed. Story generation will use templates.")
        return None
    
    if llm_instance is None:
        if not os.path.exists(LLAMA_MODEL_PATH):
            print(f"Model file not found at: {LLAMA_MODEL_PATH}")
            print("Please download a GGUF model file and place it in the models directory.")
            print("You can download from:")
            print("https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.q2_K.gguf")
            return None
        
        try:
            llm_instance = Llama(
                model_path=LLAMA_MODEL_PATH,
                n_ctx=512,  # Smaller context window to reduce memory usage
                n_threads=4  # Limit threads to reduce CPU usage
            )
        except Exception as e:
            print(f"Failed to load Llama model: {e}")
            print("Story generation will fall back to templates.")
            llm_instance = None
            return None
    return llm_instance


def generate_story(name, costume, treat):
    name = name or "Someone"
    costume = costume or "costume"
    treat = treat or "treat"
    
    prompt = (
        f"Write a short, fun Halloween story (under 60 words) about {name} "
        f"wearing a {costume} costume and involving a {treat} treat. "
        f"Make it office-friendly and either spooky, funny, adventurous, or classic."
    )
    
    llm = get_llm()
    if llm:
        try:
            output = llm(
                prompt,
                max_tokens=120,
                temperature=0.7,  # Add some randomness
                stop=["\n", ".", "!"],  # Stop at natural endpoints
                echo=False  # Don't include prompt in output
            )
     
            if output and isinstance(output, dict) and "choices" in output:
                story = output["choices"][0]["text"].strip()
                if story:
                    # Ensure story ends with punctuation
                    if not story[-1] in ".!?":
                        story += "."
                    return story
        except Exception as e:
            print(f"LLM error generating story: {e}")
            print("Falling back to template story.")
    
    # If anything fails, use template
    template = random.choice(STORY_TEMPLATES)
    return template.format(name=name, costume=costume, treat=treat)



def ensure_snapshot_dir():
    directory = state.get("snapshots_dir")
    if directory:
        os.makedirs(directory, exist_ok=True)


def compute_overlays_signature(directory):
    if not directory or not os.path.isdir(directory):
        return ()
    try:
        entries = os.listdir(directory)
    except OSError:
        return ()
    signature = []
    for name in sorted(entries):
        if not name.lower().endswith('.png') and name.lower() != 'config.json':
            continue
        path = os.path.join(directory, name)
        try:
            stat = os.stat(path)
        except OSError:
            continue
        signature.append((name, int(stat.st_mtime), int(stat.st_size)))
    return tuple(signature)


def next_snapshot_path():
    directory = state.get("snapshots_dir")
    if not directory:
        return None
    ensure_snapshot_dir()
    existing_numbers = []
    for name in os.listdir(directory):
        if not name.startswith("snap") or not name.lower().endswith(".jpg"):
            continue
        suffix = name[4:-4]
        if suffix.isdigit():
            existing_numbers.append(int(suffix))
    next_idx = max(existing_numbers) + 1 if existing_numbers else 0
    while True:
        candidate = os.path.join(directory, f"snap{next_idx:02d}.jpg")
        if not os.path.exists(candidate):
            return candidate
        next_idx += 1


def save_snapshot(frame):
    path = next_snapshot_path()
    if path is None:
        return
    try:
        cv2.imwrite(path, frame)
        state["last_snapshot_path"] = os.path.basename(path)
    except Exception:
        # Swallow errors but clear last_snapshot_path so status does not lie
        state["last_snapshot_path"] = None


def list_overlay_names():
    return [ov.get("name") for ov in state.get("overlays", [])]


def reload_overlays(force=False):
    directory = state.get("overlays_dir")
    signature = compute_overlays_signature(directory)
    if not force and signature == state.get("_overlays_signature"):
        return

    overlays = load_overlays(directory) if directory and os.path.isdir(directory) else []
    state["overlays"] = overlays
    state["_overlays_signature"] = signature
    refresh_overlay_lookup()
    active = state.get("active_overlays", []) or []
    state["active_overlays"] = [name for name in active if get_overlay_entry(name)]
    if not overlays:
        state["current_idx"] = 0
    else:
        state["current_idx"] = state.get("current_idx", 0) % len(overlays)
    target = state.get("nudge_overlay")
    if target and not get_overlay_entry(target):
        state["nudge_overlay"] = None
        set_nudge_message("Nudge target unavailable; select another overlay.")


def persist_overlays_config():
    directory = state.get("overlays_dir")
    if not directory:
        return False
    cfg_path = os.path.join(directory, "config.json")
    data = {}
    for ov in state.get("overlays") or []:
        name = ov.get("name")
        cfg = ov.get("config", {}) or {}
        if not name:
            continue
        data[name] = {
            "scale": float(cfg.get("scale", 0.9)),
            "y_offset": float(cfg.get("y_offset", 0.55)),
            "x_anchor": float(cfg.get("x_anchor", 0.5)),
            "offset_x": round(float(cfg.get("offset_x", 0.0)), 3),
            "offset_y": round(float(cfg.get("offset_y", 0.0)), 3),
        }
        if "description" in cfg:
            data[name]["description"] = cfg["description"]
    tmp_path = cfg_path + ".tmp"
    with open(tmp_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2)
    os.replace(tmp_path, cfg_path)
    state["_overlays_signature"] = compute_overlays_signature(directory)
    refresh_overlay_lookup()
    return True


def refresh_overlay_lookup():
    overlays = state.get("overlays") or []
    state["overlay_lookup"] = {
        ov.get("name", "").lower(): ov for ov in overlays if ov.get("name")
    }


def get_overlay_entry(name):
    if not name:
        return None
    lookup = state.get("overlay_lookup") or {}
    return lookup.get(name.lower())


def get_overlay_config_snapshot(name):
    entry = get_overlay_entry(name)
    if entry is None:
        return None
    cfg = entry.get("config", {}) or {}
    return {
        "scale": float(cfg.get("scale", 0.9)),
        "y_offset": float(cfg.get("y_offset", 0.55)),
        "x_anchor": float(cfg.get("x_anchor", 0.5)),
        "offset_x": float(cfg.get("offset_x", 0.0)),
        "offset_y": float(cfg.get("offset_y", 0.0)),
    }


def set_nudge_message(text):
    state["nudge_message"] = text or ""


def ensure_nudge_target():
    target = state.get("nudge_overlay")
    entry = get_overlay_entry(target)
    if entry is not None:
        return target
    active = state.get("active_overlays") or []
    for name in reversed(active):
        if get_overlay_entry(name):
            state["nudge_overlay"] = name
            return name
    state["nudge_overlay"] = None
    return None


def add_overlay_by_name(name):
    reload_overlays()
    overlays = state.get("overlays") or []
    if not overlays:
        return None
    normalized = (name or "").lower().strip()
    if not normalized.endswith('.png'):
        normalized = f"{normalized}.png"
    entry = get_overlay_entry(normalized)
    if entry is None:
        return None
    actual_name = entry.get("name")
    active = state.setdefault("active_overlays", [])
    if actual_name in active:
        active.remove(actual_name)
    active.append(actual_name)
    if state.get("nudge_mode") and actual_name:
        state["nudge_overlay"] = actual_name
        set_nudge_message("")
    return entry


def clear_active_overlays():
    state["active_overlays"] = []
    state["current_idx"] = 0
    state["nudge_overlay"] = None
    set_nudge_message("")


def arm_snapshot_wait():
    state['prod_waiting'] = True
    state['prod_frozen'] = False
    state['prod_frame'] = None
    return True


def capture_loop():
    cap = cv2.VideoCapture(0)
    cap.set(3, 640)
    cap.set(4, 480)

    ensure_snapshot_dir()
    reload_overlays()

    while state["running"]:
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.01)
            continue

        if state.get('mode') == 'dev':
            state['show_face_box'] = True

        # FPS calculation
        now = time.time()
        prev = state.get("_prev_time", None)
        if prev is None:
            state["_prev_time"] = now
        else:
            dt = now - prev
            if dt > 0:
                state["fps"] = round(1.0 / dt, 1)
            state["_prev_time"] = now

        # If in prod mode and frozen, skip capture processing and keep prod_frame
        if state.get('mode') == 'prod' and state.get('prod_frozen'):
            frozen = state.get('prod_frame')
            if frozen is not None:
                state['frame'] = frozen
            time.sleep(0.05)
            continue

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.2, 5)

        # choose best face by combined area+center heuristic
        from face1 import select_best_face

        chosen = select_best_face(faces, frame.shape[1], frame.shape[0])

        if chosen is not None:
            x, y, w, h = chosen
            if state["show_face_box"]:
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), state["face_box_thickness"])

            active_names = list(state.get("active_overlays", []))
            if active_names:
                for overlay_name in active_names:
                    entry = get_overlay_entry(overlay_name)
                    if entry is None:
                        continue
                    img = entry["image"]
                    cfg = entry.get("config", {})

                    scale = cfg.get("scale", 0.9)
                    y_offset = cfg.get("y_offset", 0.55)
                    x_anchor = cfg.get("x_anchor", 0.5)

                    overlay_w = int(w * scale)
                    aspect = img.shape[0] / img.shape[1]
                    overlay_h = int(overlay_w * aspect)

                    offset_x_pct = float(cfg.get("offset_x", 0.0))
                    offset_y_pct = float(cfg.get("offset_y", 0.0))
                    offset_x_px = int(round((offset_x_pct / 100.0) * (w / 2.0)))
                    offset_y_px = int(round((offset_y_pct / 100.0) * (h / 2.0)))

                    overlay_x = int(x + (w * x_anchor) - (overlay_w * x_anchor) + offset_x_px)
                    overlay_y = int(y + int(h * y_offset) + offset_y_px)

                    frame = overlay_transparent(frame, img, overlay_x, overlay_y, (overlay_w, overlay_h))

            # if we're in prod mode and waiting for a snapshot, freeze this frame now
            if state.get('mode') == 'prod' and state.get('prod_waiting') and not state.get('prod_frozen'):
                frozen_frame = frame.copy()
                state['prod_frame'] = frozen_frame
                state['prod_frozen'] = True
                state['prod_waiting'] = False
                save_snapshot(frozen_frame)

        # status
        if state.get('mode') != 'prod':
            active_names = state.get("active_overlays", [])
            if active_names:
                display = ", ".join(name.rsplit('.', 1)[0] for name in active_names)
                status = f"Overlays: {display}"
            else:
                status = "Overlays: none"
            cv2.putText(frame, status, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

        state["frame"] = frame
        time.sleep(0.01)

    cap.release()


@app.route('/api/set_mode', methods=['POST'])
def api_set_mode():
    m = request.args.get('mode', request.form.get('mode', 'dev'))
    if m not in ('dev', 'prod'):
        return jsonify(success=False, error='invalid mode'), 400
    state['mode'] = m
    # changing modes clears any frozen/waiting prod state so live stream resumes
    state['prod_frozen'] = False
    state['prod_frame'] = None
    state['prod_waiting'] = False
    if m == 'dev':
        state['show_face_box'] = True
    else:
        state['show_face_box'] = False
    return jsonify(success=True, mode=m)


@app.route('/api/prod_freeze', methods=['POST'])
def api_prod_freeze():
    # direct freeze (manual): freeze the current frame immediately
    if state.get('frame') is None:
        return jsonify(success=False, error='no frame'), 400
    state['prod_frame'] = state['frame'].copy()
    state['prod_frozen'] = True
    state['prod_waiting'] = False
    return jsonify(success=True)


@app.route('/api/prod_reset', methods=['POST'])
def api_prod_reset():
    # reset to waiting-for-snapshot state
    state['prod_frozen'] = False
    state['prod_frame'] = None
    state['prod_waiting'] = False
    return jsonify(success=True)


@app.route('/api/prod_snapshot', methods=['POST'])
def api_prod_snapshot():
    if state.get('mode') != 'prod':
        return jsonify(success=False, error='snapshot only available in prod mode', mode=state.get('mode')), 409
    if state.get('prod_waiting'):
        return jsonify(success=True, waiting=True, mode=state.get('mode'))
    arm_snapshot_wait()
    return jsonify(success=True, waiting=True, mode=state.get('mode'))


@app.route('/api/snapshot', methods=['POST'])
def api_snapshot():
    if state.get('mode') != 'prod':
        return jsonify(success=False, error='snapshot only available in prod mode', mode=state.get('mode')), 409
    if state.get('prod_waiting'):
        return jsonify(success=True, waiting=True, mode=state.get('mode'))
    arm_snapshot_wait()
    return jsonify(success=True, waiting=True, mode=state.get('mode'))


@app.route("/")
def index():
    return render_template("index.html")


def gen_frames():
    while True:
        frame = state.get("frame")
        if frame is None:
            time.sleep(0.01)
            continue
        # encode as jpeg
        ret, buffer = cv2.imencode('.jpg', frame)
        frame_bytes = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')


@app.route('/stream')
def stream():
    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')


@app.route('/api/toggle_overlay', methods=['POST'])
def api_toggle_overlay():
    if state.get('active_overlays'):
        clear_active_overlays()
    return jsonify(success=True, overlay=None, active_overlays=state.get('active_overlays', []))


@app.route('/api/next_overlay', methods=['POST'])
def api_next_overlay():
    overlays = state.get('overlays') or []
    added_name = None
    if overlays:
        state['current_idx'] = (state.get('current_idx', -1) + 1) % len(overlays)
        entry = overlays[state['current_idx']]
        added = add_overlay_by_name(entry.get('name'))
        if isinstance(added, dict):
            added_name = added.get('name')
    return jsonify(success=True, overlay=added_name, active_overlays=state.get('active_overlays', []))


@app.route('/api/prev_overlay', methods=['POST'])
def api_prev_overlay():
    overlays = state.get('overlays') or []
    added_name = None
    if overlays:
        state['current_idx'] = (state.get('current_idx', 0) - 1) % len(overlays)
        entry = overlays[state['current_idx']]
        added = add_overlay_by_name(entry.get('name'))
        if isinstance(added, dict):
            added_name = added.get('name')
    return jsonify(success=True, overlay=added_name, active_overlays=state.get('active_overlays', []))
